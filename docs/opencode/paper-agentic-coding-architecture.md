# 基于 Agent 循环与工具调用的自动编程架构

**与实现语言无关的技术说明**

---

## 摘要

本文描述一种使大语言模型（LLM）能够安全、可控地修改本地代码库的架构。该架构由三部分组成：（1）**Agent 循环**——在单次用户请求内，反复将对话历史与工具列表送入 LLM，根据模型输出的文本或工具调用执行本地工具，并将工具结果作为新消息追加到历史后再次调用 LLM，直到模型决定结束；（2）**LLM 提供方抽象**——统一多厂商 API 的流式响应与工具调用（Tool Use）语义；（3）**一组面向文件编辑的工具**——包括单处替换/新建/删除（edit）、多文件统一补丁（patch）、整文件覆写（write），以及读与执行类工具（如文件浏览、搜索、执行 shell）。写盘前通过权限服务请求用户授权，并通过差异计算、可选的文件变更历史与语言服务器协议（LSP）诊断提升正确性与可追溯性。系统提示词约束模型采用「先读再改、绝对路径、最小改动、不自动提交」等策略。本文以抽象组件、数据流与协议描述为主，不依赖任何具体编程语言或代码库。

**关键词**：Agent 循环；Tool Use；自动编程；LLM；ReAct；权限；diff；LSP

---

## 1. 引言

让 LLM 直接修改用户工作区中的代码，需要解决三类问题：**决策与执行的一体化**（模型何时调用何种工具、如何根据结果继续）、**与多种 LLM API 的对接**（流式输出、函数/工具调用格式不一）、**对文件系统修改的安全与可控**（避免误改、可审计、可回滚）。本文给出的架构通过一个固定的 **Agent 循环** 将「模型推理」与「工具执行」串联起来，通过 **Provider 抽象** 屏蔽各厂商 API 差异，通过 **edit / patch / write 三种编辑工具** 与 **权限服务、差异计算、历史与 LSP** 的配合，在实现层面满足上述需求。以下各节以与编程语言无关的方式定义组件、消息形态与流程，便于在不同语言与运行时中复现。

---

## 2. 架构总览

### 2.1 组件层次

- **Agent**：维护会话标识、消息历史与工具注册表；对外提供「运行一次用户请求」的入口；内部在单次运行中反复执行「把当前消息历史与工具描述发给 LLM → 接收流式输出与工具调用 → 在本地顺序执行被调用的工具 → 将助手消息与工具结果追加为两条新消息 → 用更新后的历史再次调用 LLM」，直到模型返回的结束原因为「结束回合」或发生取消/错误/权限拒绝。
- **Provider**：对 LLM 后端的抽象。至少支持：在给定消息序列与工具定义下，发起一次请求并返回**流式事件**（如文本增量、思考增量、工具调用开始/参数增量/结束、请求完成、错误）；在「请求完成」事件中提供完整工具调用列表与结束原因。不同厂商（如 OpenAI、Anthropic、Gemini 等）的 API 由各自适配器实现同一 Provider 接口，并将统一格式的工具定义转换为该 API 的 function/tool schema。
- **Tools**：可被模型按名称调用的能力单元。每个工具具有：名称、自然语言描述、参数模式（名称、类型、是否必填）；执行时接收调用标识、工具名与参数字符串（通常为 JSON），返回结果内容、可选元数据与是否出错的标志。与「写代码」直接相关的是三类文件编辑工具（见第 6 节），以及读与执行类工具（如列出目录、读取文件、搜索、执行 shell 等）。

### 2.2 数据流（单次用户请求）

1. 用户输入（文本及可选附件）与当前会话的历史消息合并，得到**当前消息历史**。
2. Agent 将**当前消息历史**与**工具定义列表**交给 Provider；Provider 向 LLM 发起请求并返回**事件流**。
3. Agent 消费事件流：累积助手消息的文本与思考内容；收集本轮的**工具调用列表**（每项含调用标识、工具名、输入参数）；在「请求完成」事件中得到**结束原因**。
4. 若结束原因为「工具调用」且存在工具调用列表：Agent 在本地按顺序执行每个工具调用，得到一组**工具结果**（每项含对应调用标识、结果内容、元数据、是否错误）；将**本轮的助手消息**与**一条由所有工具结果组成的工具消息**追加到消息历史；回到步骤 2。
5. 若结束原因为「结束回合」或其它（如达到最大 token、取消、错误、权限拒绝）：本轮结束，将最终的助手消息返回给调用方。

因此，「能写代码」在架构上等价于：**LLM 的 Tool Use 能力 + 一组可安全落盘的文件编辑工具 + 上述 Agent 循环**。

---

## 3. Agent 循环的细化

### 3.1 会话与上下文

- 每次「运行」绑定到一个**会话标识**。Agent 根据该标识加载该会话的**历史消息**（可能经过摘要截断：若会话存在「摘要消息」，则仅保留该消息及之后的消息，并将该消息视为一条用户消息作为上下文起点）。
- 用户本轮输入被持久化为一条**用户消息**（角色为用户；内容可包含文本与附件）。**当前消息历史** = 已加载的历史消息 + 该用户消息。

### 3.2 单轮「调用 LLM + 处理事件 + 执行工具」

- **调用 LLM**：Agent 以当前消息历史与工具注册表为输入，调用 Provider 的**流式接口**。Provider 将工具注册表转换为后端 API 所需的 schema，随请求发送；返回一个**事件流**。
- **处理流事件**：对每个事件按类型处理：
  - **思考增量**：追加到当前助手消息的「思考」内容并持久化。
  - **文本增量**：追加到当前助手消息的「文本」内容并持久化。
  - **工具调用开始**：为当前助手消息添加一项工具调用（标识、名称、初始参数）。
  - **工具调用结束**：标记该工具调用的参数已完整。
  - **请求完成**：用服务端返回的完整工具调用列表与结束原因更新当前助手消息并持久化；记录用量（若接口提供）。
  - **错误**：若为取消则按取消流程结束；否则向上层返回错误。
- **执行工具**：若当前助手消息包含工具调用列表，则按顺序对每一项：根据**工具名**在注册表中查找工具实现；若未找到则生成「工具未找到」的结果；若找到则传入调用标识、工具名与参数执行；若执行返回「权限拒绝」，则中止后续执行、将当前轮标记为「权限拒绝」并结束循环；否则将执行结果（调用标识、内容、元数据、是否错误）加入结果列表。最后，将**所有工具结果**持久化为一条**工具消息**（角色为工具），与当前助手消息一起作为本轮的输出。
- **决定是否继续**：若结束原因为「工具调用」且已成功生成工具结果消息，则将**当前助手消息**与**该工具消息**追加到当前消息历史，并开始下一轮（再次调用 LLM）；否则结束循环并返回当前助手消息。

### 3.3 取消与并发

- Agent 为每个会话的「当前运行」维护可取消的上下文；外部可请求取消，此时正在进行的 LLM 请求与未执行的工具调用应尽快终止，并将当前助手消息标记为「已取消」后结束。
- 同一会话在同一时刻至多允许一个运行中的请求（忙则拒绝新请求）。

---

## 4. LLM Provider 抽象

### 4.1 能力要求

- **流式接口**：输入为消息序列与工具定义；输出为**事件流**。事件至少包含：文本增量、思考增量（若模型支持）、工具调用开始/参数增量/结束、请求完成（含完整工具调用列表与结束原因）、错误。
- **非流式接口**（可选）：用于标题生成、会话摘要等辅助任务；输入同上，输出为完整响应（文本、工具调用、用量、结束原因）。
- **模型信息**：Provider 暴露当前使用的模型标识与能力（如是否支持附件、是否支持思考链等），供 Agent 做前置校验。

### 4.2 工具定义的转换

- 每个已注册工具向 Provider 提供：**名称**、**描述**（自然语言）、**参数模式**（参数名、类型、是否必填）。Provider 在发起请求前，将这些信息转换为目标 API 的 function/tool 定义（如 OpenAI 的 `tools`、Anthropic 的 `tools` 等）；模型返回的 tool_calls 由 Provider 解析为统一的**工具调用结构**（调用标识、工具名、参数字符串），通过「请求完成」事件或流中的工具调用事件交付给 Agent。

### 4.3 多后端

- 不同后端（OpenAI、Anthropic、Gemini、本地服务等）可实现同一 Provider 接口；Agent 仅依赖该接口，不关心具体后端。同一套工具定义可被不同后端的适配器转换成各自格式。

---

## 5. 消息与工具调用协议

### 5.1 消息角色

- **用户（user）**：用户输入，可包含文本与附件（如文件内容、图片）。
- **助手（assistant）**：模型输出，可包含文本、思考（若支持）、以及若干**工具调用**；消息末尾可有**结束标记**（见下）。
- **系统（system）**：系统提示词，通常由 Provider 在请求时注入，不单独持久化为会话内消息。
- **工具（tool）**：单条消息可包含多个**工具结果**，与上一条助手消息中的工具调用一一对应（通过调用标识关联）。

### 5.2 内容部件

- 一条消息由若干**内容部件**组成。典型类型：纯文本、思考内容、图片、二进制附件、**工具调用**（标识、名称、参数、是否已结束）、**工具结果**（调用标识、名称、内容、元数据、是否错误）、**结束标记**（结束原因、时间戳）。
- **结束原因** 取值包括：结束回合、达到最大 token、**工具调用**（表示模型希望执行工具，需继续循环）、已取消、错误、权限拒绝等。当且仅当结束原因为「工具调用」且存在工具结果时，Agent 继续下一轮。

### 5.3 工具调用与结果的对应

- 助手消息中可包含多个工具调用；执行顺序与消息内顺序一致。每条工具结果通过**调用标识**与某一条工具调用关联。工具消息按相同顺序列出所有结果，Agent 将整条工具消息与上一条助手消息一起追加到历史，供下一轮 LLM 使用。

---

## 6. 文件编辑工具

以下三种工具是「能写代码」的核心；均假设在写盘前通过**权限服务**请求用户授权，若用户拒绝则返回「权限拒绝」，Agent 终止本轮并标记为权限拒绝。

### 6.1 Edit（单处替换 / 新建 / 删除）

- **语义**：对单个文件做**一次**基于字符串匹配的替换，或新建文件，或删除一段内容。
- **参数**：文件路径（建议绝对路径）、旧字符串、新字符串。
  - **新建**：旧字符串为空；新字符串为完整内容；要求目标路径下文件尚不存在。
  - **删除**：新字符串为空；旧字符串为要删除的片段；要求该片段在文件中**唯一出现**（见下）。
  - **替换**：旧字符串被新字符串替换一次；同样要求**唯一匹配**。
- **约束**：
  - **先读再改**：目标文件必须在本次会话内曾被「读」类工具（如 View）读过，且自上次读到当前时刻未被外部修改；否则拒绝操作并提示先读。
  - **唯一性**：旧字符串在文件中的出现次数必须为 1（通过首尾索引相等判定）；若出现多次则要求调用方提供更多上下文以缩小到唯一位置。
- **流程**：解析参数 → 若为新建则检查不存在并计算 diff（空→内容）；若为删除或替换则读文件、校验先读与唯一性、计算新内容与 diff → 请求权限 → 写盘 → 可选地更新文件变更历史、触发 LSP 诊断并将诊断信息附在返回内容后。

### 6.2 Patch（多文件统一补丁）

- **语义**：在一次调用中，对多个文件应用**一组**变更（增/改/删），格式为自定义的块式 patch 文本（如「开始补丁」「更新文件 path」「添加文件 path」「删除文件 path」「结束补丁」及类 unified diff 的上下文行与增删行）。
- **参数**：补丁文本。
- **约束**：
  - 所有被「更新」或「删除」的文件必须先被读过，且自上次读以来未修改；所有被「添加」的路径必须尚不存在。
  - 补丁解析可产生**模糊度**（上下文匹配不精确）；当模糊度超过设定阈值时拒绝应用并建议提供更精确的上下文。
- **流程**：从补丁文本中识别涉及的文件路径（需读取的、需新增的）→ 校验先读与未修改、新增路径不存在 → 加载当前文件内容 → 解析补丁为**变更计划**（每路径一个动作：增/改/删及旧/新内容）→ 对每个变更生成展示用 diff 并请求权限 → 按计划依次写盘或删文件 → 更新历史与 LSP、汇总变更统计与诊断后返回。

### 6.3 Write（整文件覆写）

- **语义**：将给定路径的文件内容整体替换为给定内容；若文件不存在则创建。
- **参数**：文件路径、内容。
- **约束**：若文件已存在，须满足「先读再改」且自上次读以来未修改；若当前内容与请求内容相同则可不写盘直接返回「无变更」。
- **流程**：校验 → 计算 diff（旧内容→新内容）→ 请求权限 → 写盘 → 历史与 LSP、返回带 diff 统计的元数据。

### 6.4 共同依赖

- **差异计算**：提供「生成可读 diff（旧内容、新内容、路径）→ 文本 diff + 增/删行数」；用于权限请求时的展示与工具返回的元数据。
- **权限服务**：写盘或删文件前，以会话、路径、工具名、动作、描述与 diff 等为参数请求授权；返回允许/拒绝。拒绝时工具返回「权限拒绝」，由 Agent 统一处理。
- **文件变更历史**（可选）：按会话与路径记录每次写盘前后的内容版本，便于追溯与回滚。
- **LSP / 诊断**（可选）：写盘后可等待语言服务器诊断，并将诊断结果（错误、警告）附加到工具返回内容中，供模型在下一轮中修正。

---

## 7. 差异与补丁

### 7.1 差异生成

- 给定两个字符串（旧内容、新内容）与可选的文件路径，生成人类可读的 diff 文本及增行数、删行数。用于：权限请求时的变更展示；编辑工具返回的元数据。

### 7.2 补丁解析与应用

- **解析**：输入为补丁文本与当前各路径下的文件内容（path → content）；输出为**补丁结构**（每路径对应一组「行级删除/插入」或「新增/删除文件」）及**模糊度**。若模糊度超过阈值则拒绝应用。
- **变更计划**：将补丁结构转换为对文件系统的**原子变更计划**（每路径一个动作：添加、更新、删除，及对应的旧内容与新内容）。
- **应用**：按变更计划依次执行「写文件」或「删文件」；写文件时若目录不存在则先创建。可由调用方注入具体的写/删实现（如解析相对路径为绝对路径、创建父目录等）。

### 7.3 从补丁文本识别路径

- 提供从补丁文本中提取「需要读取当前内容的路径」与「将要新增的路径」的能力，供 Patch 工具做「先读再改」与「新增路径不存在」的校验。

---

## 8. 系统提示词与行为约束

### 8.1 角色与目标

- 系统提示词将助手定义为「面向终端的、可修改代码的编程助手」，要求**在问题解决前持续执行**，仅在确信任务完成或无法继续时结束回合；不要猜测文件内容或结构，应使用读类工具获取信息。

### 8.2 编辑规范

- **先读再改**：需要修改前先用读/浏览工具查看文件与路径，再使用 edit / patch / write。
- **路径**：使用绝对路径（或约定由系统将相对路径解析为基于工作目录的绝对路径）；一次 edit 只改一处；多处修改用多次 edit 或一次 patch。
- **自检**：改完后可用版本控制状态或 diff 自检；不自动提交除非用户明确要求。
- **风格**：回复简洁，少前言后语，适合终端展示；无依赖的多个工具调用可同批发出以节省轮次。

### 8.3 环境与 LSP

- 系统提示词可动态注入**环境信息**（工作目录、是否在版本库中、平台、日期、项目根目录列表等），以及若启用 LSP 则说明「工具返回中可能包含诊断，请根据诊断修复问题」。不同 LLM 后端可使用略有差别的 base 提示词，但都强调读→改→查与最小改动。

---

## 9. Agent 与 Planner：架构选择与学术脉络

本节着重区分**反应式 Agent（ReAct 式）**与**先规划再执行（Plan-and-Execute）**两类架构，并对照学术界对 LLM-Agent 规划能力的分类，说明本架构的定位与取舍。

### 9.1 本架构中的 Agent：ReAct 式循环执行体

- 本架构中的 **Agent** 指第 2、3 节定义的**循环执行体**：每轮由 LLM 根据当前消息历史直接决定输出文本或发起工具调用，执行后将结果写回消息并继续下一轮，**不先显式生成多步计划**。
- 该模式对应 **ReAct**（Reasoning + Acting）范式：推理（Thought）与行动（Action）交替进行，每步决策都基于**当前环境反馈**（工具结果、历史消息），形成「观察 → 推理 → 行动 → 观察」的闭环。
- **特点**：规划隐含在模型的逐轮输出中，通过系统提示词约束「先读再改、最小改动」等策略，通过工具选择与参数体现「下一步做什么」；无独立规划节点，无显式步骤列表或 DAG。

### 9.2 Plan-and-Execute（Planner）架构

- **Plan-and-Execute** 将**规划**与**执行**分离：先由「规划」模块（常为 LLM）产出显式多步计划（如步骤列表、子目标序列或 DAG），再由「执行」模块按计划逐步调用工具或子模型；子任务可并行或交给更小/专用模型。
- **典型优势**（据业界与综述）：多步工作流可减少每步都调用大模型的次数，有利于**成本与延迟**；前置显式推理可提升**复杂多步任务**的完成率；计划在执行前确定，对**间接提示注入**等攻击在控制流上更易约束。
- **典型劣势**：计划一旦错误或环境变化，需额外机制（如重规划、Reflection）修正；对需**实时适应**或反馈密集的任务，先规划再执行可能不够灵活。

### 9.3 ReAct 与 Plan-and-Execute 的对比与选用

| 维度 | ReAct（本架构） | Plan-and-Execute |
|------|-----------------|------------------|
| 规划形式 | 隐式，每轮一步，由 LLM 即时决策 | 显式，多步计划先产出再执行 |
| 环境反馈 | 每步都依赖上一步的工具/观察结果 | 执行阶段才密集依赖环境，规划阶段可少依赖 |
| 成本/延迟 | 每步一次 LLM 调用，步数多时成本高 | 规划一次、执行可复用或交给轻量模块，常更省 |
| 适应性 | 高，可随时根据结果改策略 | 依赖重规划或 Reflection，否则适应性较低 |
| 适用场景 | 探索性强、需实时纠错、步数不一定多的任务（如交互式改代码） | 步骤多、结构清晰、可预先拆解的任务 |

本架构选择 ReAct 式 Agent 的原因包括：自动编程场景中「读→改→查」强依赖**当前文件状态与 LSP 诊断**，每步决策需紧跟最新反馈；先验多步计划易因代码库复杂与用户意图模糊而失效；实现简单、无独立规划器与执行器状态机，便于多后端与多语言复现。

### 9.4 学术界对 LLM-Agent 规划的分类（综述对照）

Huang 等（2024）在 *Understanding the planning of LLM agents: A survey*（arXiv:2402.02716）中给出 LLM-Agent 规划的首个系统分类，将现有工作归纳为五类，可与本架构对照如下：

1. **Task Decomposition（任务分解）**  
   - **Decomposition-first**：先完整分解再逐子任务规划（如 HuggingGPT、Plan-and-Solve），对应「Plan-and-Execute」思路。  
   - **Interleaved decomposition**：分解与执行交错，每步只展开少量子目标并立即执行（如 ReAct、CoT），对应**本架构**：无显式分解步骤，但「每一步选哪个工具、改哪处」等价于即时子目标选择。

2. **Plan Selection（多计划选择）**  
   生成多条候选计划并用搜索/启发式选优（如 Tree-of-Thought、LLM-MCTS）。本架构**不采用**多计划生成与搜索，以单轨迹、流式决策为主，以控制复杂度和延迟。

3. **External Module（外部规划模块）**  
   LLM 负责形式化任务，外部符号/神经规划器负责生成计划（如 LLM+P/PDDL、SwiftSage）。本架构**不引入**外部规划器，规划完全由 LLM 与工具描述、提示词承担。

4. **Reflection and Refinement（反思与精炼）**  
   根据执行结果反思并修正计划（如 Reflexion、Self-Refine、CRITIC）。本架构**未**内置独立 Reflection 模块，但「工具结果写回历史 → 下一轮 LLM 根据结果继续」在行为上允许模型根据 LSP 诊断、权限拒绝等反馈做**隐式反思与下一步修正**；若需更强纠错，可在上层增加反思/重试策略。

5. **Memory-augmented Planning（记忆增强规划）**  
   从外部记忆（RAG、向量库、知识图谱等）检索经验以辅助规划。本架构依赖**会话内消息历史**（及可选的摘要截断）作为短期记忆；若产品需要长期记忆或跨会话经验，可在 Agent 之外增加记忆模块与检索接口，而不改变核心循环。

综上，本架构在学术分类上属于 **Task Decomposition 的 Interleaved 分支**（ReAct 式），不采用独立 Planner、多计划搜索或外部符号规划器；规划能力由**系统提示词 + 工具集 + 消息历史**共同承担，与「Agent 循环 + Provider 抽象 + 编辑工具」一起构成「能安全写代码」的最小闭环。

### 9.5 配置命名说明

- 配置中的「Plan」若指**只读代理**（仅开放读与搜索类工具、不开放写与执行），与架构上的「规划器（Planner）」无直接对应，仅为代理配置的一种命名（例如「仅规划/探索、不落盘」的用法）。

---

## 10. 结论

本文以与实现语言无关的方式描述了「使 LLM 能安全写代码」的架构：**Agent 循环**（消息历史 + 流式 LLM 调用 + 工具执行 + 结果写回历史并继续）负责决策与执行的衔接；**Provider 抽象**负责多后端与 Tool Use 的统一；**edit / patch / write** 三种工具在**先读再改、唯一匹配、权限请求、diff、历史与 LSP** 的约束下完成对文件系统的修改。系统提示词约束模型按「读→改→查」与最小改动行事，且不自动提交。该设计可在任意语言与运行时中实现，只需满足上述组件接口与数据流即可复现「能写代码」的核心行为。

---

## 参考文献（建议）

- ReAct: Synergizing Reasoning and Acting in Language Models (Yao et al.).
- 各 LLM API 文档：OpenAI Function Calling, Anthropic Tool Use, 等.
- Language Server Protocol (LSP) 规范.
- Unified Diff 格式 (e.g., POSIX diff).
